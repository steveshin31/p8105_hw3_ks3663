---
title: "p8105_hw3_ks3663"
author: "Kee-Young Shin"
date: "October 10, 2018"
output: github_document
---

## Problem 1
```{r}

library(tidyverse)
library(p8105.datasets)

data("brfss_smart2010") 

filtered_brfss = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>%
  mutate(response_f = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"), ordered = TRUE))

levels(filtered_brfss$response_f)
filtered_brfss
class(filtered_brfss$response_f)

```
```{r}

filtered_brfss %>%
  filter(year == "2002") %>%
  select(locationabbr, locationdesc) %>%
  distinct() %>%
  group_by(locationabbr) %>%
  summarize(count = n()) %>%
  filter(count == 7)
# CT, FL, and NC

spaghetti_data = filtered_brfss %>%
  select(year, locationabbr, locationdesc) %>%
  distinct() %>%
  group_by(year, locationabbr) %>%
  summarize(count = n())
spaghetti_data

ggplot(spaghetti_data, aes(x = year, y = count, color = locationabbr)) + 
  geom_line()

```
```{r}

filtered_brfss %>%
  filter(locationabbr == "NY", year %in% c(2002, 2006, 2010)) %>%
  select(locationabbr, locationdesc, year, response_f, sample_size) %>%
  spread(response_f, value = sample_size) %>%
  mutate(proportion_ex = Excellent / (Excellent + `Very good` + Good + Fair + Poor)) %>%
  group_by(year) %>%
  summarize(mean = mean(proportion_ex), std = sd(proportion_ex)) 
  

```

```{r}

average_data = filtered_brfss %>%
  select(locationabbr, locationdesc, year, response_f, sample_size) %>%
  spread(response_f, value = sample_size) %>%
  mutate(total_sample = (Excellent + `Very good` + Good + Fair + Poor)) %>%
  mutate(proportion_ex = Excellent / total_sample, proportion_vg = `Very good` / total_sample, proportion_g = Good / total_sample, proportion_f = Fair / total_sample, proportion_p = Poor / total_sample) %>%
  group_by(year, locationabbr) %>%
  summarize(mean_ex = mean(proportion_ex), mean_vg = mean(proportion_vg), mean_g = mean(proportion_g), mean_f = mean(proportion_f), mean_p = mean(proportion_p)) %>%
  ungroup() %>%
  gather(key = variable, value = value, 3:7)

average_data

ggplot(average_data, aes(x = year, y = value, color = locationabbr)) + 
  geom_line() + facet_wrap(~variable)


```

## Problem 2
```{r}

data("instacart")

cart_data = instacart

cart_data



dim(cart_data)
```
There are 
```{r}

distinct(instacart, aisle_id) 
# There are 134 different aisles. 

instacart %>%
  group_by(aisle_id) %>% # group by aisle id
  summarize(n = n()) %>% # take count of number of times ordered 
  arrange(-n) # puts the aisle id in order from most ordered to least
# Most items are ordered from aisle 83 and aisle 24. 


aisle_data = instacart %>%
  group_by(aisle_id) %>% # group by aisle id
  summarize(n = n())  # take count of number of times ordered 
  
aisle_data

ggplot(aisle_data, aes(x = aisle_id, y = n)) + geom_point()


instacart %>%
  filter(aisle %in% c("dog food care", "baking ingredients", "packaged vegetables fruits")) %>%
  group_by(product_name, aisle) %>%
  summarize(count = n()) %>%
  ungroup() %>%
  group_by(aisle) %>%
  arrange(desc(count)) %>%
  slice(1)


```
```{r}

instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(order_dow, mean_hour)

```


## Problem 3
```{r}
data("ny_noaa")
ny_noaa

weather_data = ny_noaa %>%
  janitor::clean_names() %>%
  mutate(tmax = as.numeric(tmax), tmin = as.numeric(tmin)) %>%
  separate(date, into = c("year", "month", "day")) %>%
  mutate(year = as.numeric(year), month = as.numeric(month), day = as.numeric(day)) %>%
  mutate(prcp = prcp * 0.0393701, snow = snow * 0.0393701, snwd = snwd * 0.0393701, tmax = tmax / 10, tmin = tmin / 10) 
weather_data

ggplot(weather_data, aes(x = snow)) + 
  geom_histogram(na.rm = T, binwidth = 1) +
  coord_cartesian(xlim = c(0,25)) # snows a lot of the times but rarely a large amount

summary(weather_data$tmax)
weather_data
```

