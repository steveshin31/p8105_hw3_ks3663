p8105\_hw3\_ks3663
================
Kee-Young Shin
October 10, 2018

Problem 1
---------

``` r
library(tidyverse)
```

    ## -- Attaching packages ---------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts ------------------------------------------------- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(p8105.datasets)

data("brfss_smart2010") # import data

filtered_brfss = brfss_smart2010 %>%
  janitor::clean_names() %>%
  select(year, locationabbr, locationdesc, topic, response, sample_size, data_value) %>%
  filter(topic == "Overall Health") %>% # filter based on overall health
  mutate(response_f = factor(response, levels = c("Excellent", "Very good", "Good", "Fair", "Poor"), ordered = TRUE)) # make column for factor variables 

levels(filtered_brfss$response_f)
```

    ## [1] "Excellent" "Very good" "Good"      "Fair"      "Poor"

``` r
class(filtered_brfss$response_f)
```

    ## [1] "ordered" "factor"

``` r
filtered_brfss
```

    ## # A tibble: 10,625 x 8
    ##     year locationabbr locationdesc topic response sample_size data_value
    ##    <int> <chr>        <chr>        <chr> <chr>          <int>      <dbl>
    ##  1  2010 AL           AL - Jeffer~ Over~ Excelle~          94       18.9
    ##  2  2010 AL           AL - Jeffer~ Over~ Very go~         148       30  
    ##  3  2010 AL           AL - Jeffer~ Over~ Good             208       33.1
    ##  4  2010 AL           AL - Jeffer~ Over~ Fair             107       12.5
    ##  5  2010 AL           AL - Jeffer~ Over~ Poor              45        5.5
    ##  6  2010 AL           AL - Mobile~ Over~ Excelle~          91       15.6
    ##  7  2010 AL           AL - Mobile~ Over~ Very go~         177       31.3
    ##  8  2010 AL           AL - Mobile~ Over~ Good             224       31.2
    ##  9  2010 AL           AL - Mobile~ Over~ Fair             120       15.5
    ## 10  2010 AL           AL - Mobile~ Over~ Poor              66        6.4
    ## # ... with 10,615 more rows, and 1 more variable: response_f <ord>

``` r
filtered_brfss %>%
  filter(year == "2002") %>%
  select(locationabbr, locationdesc) %>%
  distinct() %>%
  group_by(locationabbr) %>%
  summarize(count = n()) %>%
  filter(count == 7)
```

    ## # A tibble: 3 x 2
    ##   locationabbr count
    ##   <chr>        <int>
    ## 1 CT               7
    ## 2 FL               7
    ## 3 NC               7

``` r
# CT, FL, and NC were observed at 7 locations

locations_count = filtered_brfss %>%
  select(year, locationabbr, locationdesc) %>%
  distinct() %>% # distinct states
  group_by(year, locationabbr) %>%
  summarize(count = n()) # count number of locations
locations_count
```

    ## # A tibble: 443 x 3
    ## # Groups:   year [?]
    ##     year locationabbr count
    ##    <int> <chr>        <int>
    ##  1  2002 AK               1
    ##  2  2002 AL               1
    ##  3  2002 AR               1
    ##  4  2002 AZ               2
    ##  5  2002 CA               1
    ##  6  2002 CO               4
    ##  7  2002 CT               7
    ##  8  2002 DC               1
    ##  9  2002 DE               3
    ## 10  2002 FL               7
    ## # ... with 433 more rows

``` r
ggplot(locations_count, aes(x = year, y = count, color = locationabbr)) + 
  geom_line()
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-2-1.png)

``` r
filtered_brfss %>%
  select(locationabbr, locationdesc, year, data_value, response) %>%
  filter(locationabbr == "NY", year %in% c(2002, 2006, 2010), 
         response == "Excellent") %>%
  group_by(year) %>%
  summarize(mean = mean(data_value), std = sd(data_value)) # show mean and std
```

    ## # A tibble: 3 x 3
    ##    year  mean   std
    ##   <int> <dbl> <dbl>
    ## 1  2002  24.0  4.49
    ## 2  2006  22.5  4.00
    ## 3  2010  22.7  3.57

``` r
filtered_brfss %>%
  filter(locationabbr == "NY", year %in% c(2002, 2006, 2010)) %>%
  select(locationabbr, locationdesc, year, response_f, sample_size) %>%
  spread(response_f, value = sample_size) %>%
  mutate(proportion_ex = Excellent / (Excellent + `Very good` + Good + Fair + Poor)) %>%
  group_by(year) %>%
  summarize(mean = mean(proportion_ex), std = sd(proportion_ex)) 
```

    ## # A tibble: 3 x 3
    ##    year  mean    std
    ##   <int> <dbl>  <dbl>
    ## 1  2002 0.248 0.0398
    ## 2  2006 0.218 0.0387
    ## 3  2010 0.203 0.0460

``` r
average_proportions = filtered_brfss %>%
  select(locationabbr, locationdesc, year, response_f, sample_size) %>%
  spread(response_f, value = sample_size) %>%
  mutate(total_sample = (Excellent + `Very good` + Good + Fair + Poor)) %>%
  mutate(proportion_ex = Excellent / total_sample, proportion_vg = `Very good` / total_sample, proportion_g = Good / total_sample, proportion_f = Fair / total_sample, proportion_p = Poor / total_sample) %>% # create column for averages
  group_by(year, locationabbr) %>% # group by year and location
  summarize(mean_ex = mean(proportion_ex), mean_vg = mean(proportion_vg), mean_g = mean(proportion_g), mean_f = mean(proportion_f), mean_p = mean(proportion_p)) %>%
  ungroup() %>%
  gather(key = variable, value = value, 3:7) # reorder dataset 

average_proportions
```

    ## # A tibble: 2,215 x 4
    ##     year locationabbr variable value
    ##    <int> <chr>        <chr>    <dbl>
    ##  1  2002 AK           mean_ex  0.279
    ##  2  2002 AL           mean_ex  0.187
    ##  3  2002 AR           mean_ex  0.237
    ##  4  2002 AZ           mean_ex  0.238
    ##  5  2002 CA           mean_ex  0.250
    ##  6  2002 CO           mean_ex  0.227
    ##  7  2002 CT           mean_ex  0.283
    ##  8  2002 DC           mean_ex  0.313
    ##  9  2002 DE           mean_ex  0.206
    ## 10  2002 FL           mean_ex  0.258
    ## # ... with 2,205 more rows

``` r
ggplot(average_proportions, aes(x = year, y = value, color = locationabbr)) + 
  geom_line() + facet_wrap(~variable) # create plot of the averages 
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-4-1.png)

Problem 2
---------

``` r
data("instacart") # import data

instacart
```

    ## # A tibble: 1,384,617 x 15
    ##    order_id product_id add_to_cart_ord~ reordered user_id eval_set
    ##       <int>      <int>            <int>     <int>   <int> <chr>   
    ##  1        1      49302                1         1  112108 train   
    ##  2        1      11109                2         1  112108 train   
    ##  3        1      10246                3         0  112108 train   
    ##  4        1      49683                4         0  112108 train   
    ##  5        1      43633                5         1  112108 train   
    ##  6        1      13176                6         0  112108 train   
    ##  7        1      47209                7         0  112108 train   
    ##  8        1      22035                8         1  112108 train   
    ##  9       36      39612                1         0   79431 train   
    ## 10       36      19660                2         1   79431 train   
    ## # ... with 1,384,607 more rows, and 9 more variables: order_number <int>,
    ## #   order_dow <int>, order_hour_of_day <int>,
    ## #   days_since_prior_order <int>, product_name <chr>, aisle_id <int>,
    ## #   department_id <int>, aisle <chr>, department <chr>

``` r
dim(instacart)
```

    ## [1] 1384617      15

There are

``` r
distinct(instacart, aisle_id) 
```

    ## # A tibble: 134 x 1
    ##    aisle_id
    ##       <int>
    ##  1      120
    ##  2      108
    ##  3       83
    ##  4       95
    ##  5       24
    ##  6       21
    ##  7        2
    ##  8      115
    ##  9       53
    ## 10      123
    ## # ... with 124 more rows

``` r
# There are 134 different aisles. 

instacart %>%
  group_by(aisle_id) %>% # group by aisle id
  summarize(n = n()) %>% # take count of number of times ordered 
  arrange(-n) # puts the aisle id in order from most ordered to least
```

    ## # A tibble: 134 x 2
    ##    aisle_id      n
    ##       <int>  <int>
    ##  1       83 150609
    ##  2       24 150473
    ##  3      123  78493
    ##  4      120  55240
    ##  5       21  41699
    ##  6      115  36617
    ##  7       84  32644
    ##  8      107  31269
    ##  9       91  26240
    ## 10      112  23635
    ## # ... with 124 more rows

``` r
# Most items are ordered from aisle 83 and aisle 24. 


aisle_orders = instacart %>%
  group_by(aisle_id) %>% # group by aisle id
  summarize(n = n())  # take count of number of times ordered 
  
aisle_orders
```

    ## # A tibble: 134 x 2
    ##    aisle_id     n
    ##       <int> <int>
    ##  1        1  2936
    ##  2        2  3873
    ##  3        3 17449
    ##  4        4  9917
    ##  5        5  2905
    ##  6        6  1795
    ##  7        7  1526
    ##  8        8  1501
    ##  9        9  9736
    ## 10       10   448
    ## # ... with 124 more rows

``` r
ggplot(aisle_orders, aes(x = aisle_id, y = n)) + geom_point()
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-6-1.png)

``` r
instacart %>%
  filter(aisle %in% c("dog food care", "baking ingredients", "packaged vegetables fruits")) %>% # filter by selected aisles 
  group_by(product_name, aisle) %>%
  summarize(count = n()) %>% # take count 
  ungroup() %>%
  group_by(aisle) %>%
  arrange(desc(count)) %>% # arrange count in descending order 
  slice(1) # show most ordered item 
```

    ## # A tibble: 3 x 3
    ## # Groups:   aisle [3]
    ##   product_name                               aisle                   count
    ##   <chr>                                      <chr>                   <int>
    ## 1 Light Brown Sugar                          baking ingredients        499
    ## 2 Snack Sticks Chicken & Rice Recipe Dog Tr~ dog food care              30
    ## 3 Organic Baby Spinach                       packaged vegetables fr~  9784

``` r
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% # calculate mean 
  spread(order_dow, mean_hour) # spread days into columns 
```

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

Problem 3
---------

``` r
data("ny_noaa")
ny_noaa
```

    ## # A tibble: 2,595,176 x 7
    ##    id          date        prcp  snow  snwd tmax  tmin 
    ##    <chr>       <date>     <int> <int> <int> <chr> <chr>
    ##  1 US1NYAB0001 2007-11-01    NA    NA    NA <NA>  <NA> 
    ##  2 US1NYAB0001 2007-11-02    NA    NA    NA <NA>  <NA> 
    ##  3 US1NYAB0001 2007-11-03    NA    NA    NA <NA>  <NA> 
    ##  4 US1NYAB0001 2007-11-04    NA    NA    NA <NA>  <NA> 
    ##  5 US1NYAB0001 2007-11-05    NA    NA    NA <NA>  <NA> 
    ##  6 US1NYAB0001 2007-11-06    NA    NA    NA <NA>  <NA> 
    ##  7 US1NYAB0001 2007-11-07    NA    NA    NA <NA>  <NA> 
    ##  8 US1NYAB0001 2007-11-08    NA    NA    NA <NA>  <NA> 
    ##  9 US1NYAB0001 2007-11-09    NA    NA    NA <NA>  <NA> 
    ## 10 US1NYAB0001 2007-11-10    NA    NA    NA <NA>  <NA> 
    ## # ... with 2,595,166 more rows

``` r
weather_data = ny_noaa %>%
  janitor::clean_names() %>%
  mutate(tmax = as.numeric(tmax), tmin = as.numeric(tmin)) %>%
  separate(date, into = c("year", "month", "day")) %>%
  mutate(year = as.numeric(year), month = as.numeric(month), 
         day = as.numeric(day)) %>% # make date into three separate columns 
  mutate(prcp = prcp * 0.0393701, snow = snow * 0.0393701, 
         snwd = snwd * 0.0393701, tmax = tmax / 10, 
         tmin = tmin / 10) # convert data into inches 
weather_data
```

    ## # A tibble: 2,595,176 x 9
    ##    id           year month   day  prcp  snow  snwd  tmax  tmin
    ##    <chr>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ##  1 US1NYAB0001  2007    11     1    NA    NA    NA    NA    NA
    ##  2 US1NYAB0001  2007    11     2    NA    NA    NA    NA    NA
    ##  3 US1NYAB0001  2007    11     3    NA    NA    NA    NA    NA
    ##  4 US1NYAB0001  2007    11     4    NA    NA    NA    NA    NA
    ##  5 US1NYAB0001  2007    11     5    NA    NA    NA    NA    NA
    ##  6 US1NYAB0001  2007    11     6    NA    NA    NA    NA    NA
    ##  7 US1NYAB0001  2007    11     7    NA    NA    NA    NA    NA
    ##  8 US1NYAB0001  2007    11     8    NA    NA    NA    NA    NA
    ##  9 US1NYAB0001  2007    11     9    NA    NA    NA    NA    NA
    ## 10 US1NYAB0001  2007    11    10    NA    NA    NA    NA    NA
    ## # ... with 2,595,166 more rows

``` r
ggplot(weather_data, aes(x = snow)) + 
  geom_histogram(na.rm = T, binwidth = 1) +
  coord_cartesian(xlim = c(0,25)) 
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-9-1.png)

``` r
# The most commonly observed values are small numbers close to 0. This is because 
# when it snows, it only snows a little amount. 
```

``` r
avg_tmax_df = weather_data %>%
  filter(month %in% c(1, 7), !is.na(tmax)) %>% # filter by month and exclude NA's 
  group_by(id, year, month) %>%  
  summarize(avg_tmax = mean(tmax)) # calculate averages 
avg_tmax_df  
```

    ## # A tibble: 8,141 x 4
    ## # Groups:   id, year [?]
    ##    id           year month avg_tmax
    ##    <chr>       <dbl> <dbl>    <dbl>
    ##  1 USC00300023  1981     1    -3.17
    ##  2 USC00300023  1981     7    28.3 
    ##  3 USC00300023  1982     1    -4.32
    ##  4 USC00300023  1982     7    27.8 
    ##  5 USC00300023  1983     1     1.11
    ##  6 USC00300023  1983     7    29.8 
    ##  7 USC00300023  1984     7    27.2 
    ##  8 USC00300023  1985     1    -1.30
    ##  9 USC00300023  1989     7    27.1 
    ## 10 USC00300023  1990     1     4.92
    ## # ... with 8,131 more rows

``` r
ggplot(avg_tmax_df, aes(x = year, y = avg_tmax, color = id)) +
  geom_line() + theme(legend.position = "none") + facet_wrap(~month, nrow = 2)
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-10-1.png)

``` r
avg_temp_year = weather_data %>%
  filter(!is.na(tmax) & !is.na(tmin)) %>%
  group_by(year) %>%
  summarize(avg_tmax = mean(tmax), avg_tmin = mean(tmin)) %>%
  gather(key = variable, value = value, 2:3)
avg_temp_year
```

    ## # A tibble: 60 x 3
    ##     year variable value
    ##    <dbl> <chr>    <dbl>
    ##  1  1981 avg_tmax  13.6
    ##  2  1982 avg_tmax  13.7
    ##  3  1983 avg_tmax  14.1
    ##  4  1984 avg_tmax  13.8
    ##  5  1985 avg_tmax  13.8
    ##  6  1986 avg_tmax  13.7
    ##  7  1987 avg_tmax  14.0
    ##  8  1988 avg_tmax  13.7
    ##  9  1989 avg_tmax  13.2
    ## 10  1990 avg_tmax  15.0
    ## # ... with 50 more rows

``` r
ggplot(avg_temp_year, aes(x = year, y = value)) +
  geom_line() + facet_wrap(~variable, nrow = 2, scales = "free_y") 
```

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-11-1.png)

``` r
snowfall_df = weather_data %>%
  filter(snow > 0 & snow < 100) # filter for 0 < snow < 100
  
snowfall_df  
```

    ## # A tibble: 205,442 x 9
    ##    id           year month   day  prcp  snow   snwd  tmax  tmin
    ##    <chr>       <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>
    ##  1 US1NYAB0001  2007    11    17 0.118 0.118  0        NA    NA
    ##  2 US1NYAB0001  2007    11    24 0.118 0.118  0        NA    NA
    ##  3 US1NYAB0001  2007    11    26 0.315 0.197 NA        NA    NA
    ##  4 US1NYAB0001  2007    11    28 0.315 0.197  0        NA    NA
    ##  5 US1NYAB0001  2007    12     1 1.81  2.52   2.52     NA    NA
    ##  6 US1NYAB0001  2007    12     3 4.61  0.512  0.984    NA    NA
    ##  7 US1NYAB0001  2007    12     4 0.591 1.18   2.01     NA    NA
    ##  8 US1NYAB0001  2007    12     5 0.197 0.315  2.01     NA    NA
    ##  9 US1NYAB0001  2007    12     6 0.118 0.197  2.01     NA    NA
    ## 10 US1NYAB0001  2007    12    10 1.81  0.118  0.984    NA    NA
    ## # ... with 205,432 more rows

``` r
ggplot(snowfall_df, aes(x = snow)) +
  geom_histogram() + facet_wrap(~year) # separate graphs for each year 
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

![](hw3_ks3663_files/figure-markdown_github/unnamed-chunk-11-2.png)
